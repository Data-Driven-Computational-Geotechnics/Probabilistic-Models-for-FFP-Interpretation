{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9PqPmgY8ji1"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# 1) IMPORTS\n",
        "# ===============================================================\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    r2_score, mean_absolute_percentage_error,\n",
        "    mean_squared_error, mean_absolute_error\n",
        ")\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from google.colab import drive\n",
        "import openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 2) MOUNT GOOGLE DRIVE\n",
        "# ===============================================================\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xYP5Kl-b8nlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 3) DEFINE FILE PATHS AND ENSURE DIRECTORIES EXIST\n",
        "# ===============================================================\n",
        "base_dir = '/content/drive/My Drive/Optimization of Monte Carlo Dropout-ANN'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "metrics_file_path = f'{base_dir}/Metrics_MCD_ANN_Live.xlsx'\n",
        "training_predictions_file_path = f'{base_dir}/Training_Predictions_MCD_ANN_Live.xlsx'\n",
        "testing_predictions_file_path  = f'{base_dir}/Testing_Predictions_MCD_ANN_Live.xlsx'\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Create empty Excel placeholders\n",
        "# ---------------------------------------------------------------\n",
        "if not os.path.exists(training_predictions_file_path):\n",
        "    with pd.ExcelWriter(training_predictions_file_path, engine='openpyxl') as writer:\n",
        "        pd.DataFrame().to_excel(writer, sheet_name='Init', index=False)\n",
        "\n",
        "if not os.path.exists(testing_predictions_file_path):\n",
        "    with pd.ExcelWriter(testing_predictions_file_path, engine='openpyxl') as writer:\n",
        "        pd.DataFrame().to_excel(writer, sheet_name='Init', index=False)\n",
        "\n",
        "if not os.path.exists(metrics_file_path):\n",
        "    with pd.ExcelWriter(metrics_file_path, engine='openpyxl') as writer:\n",
        "        pd.DataFrame(columns=[\n",
        "            'Iteration', 'R2_Train', 'R2_Test',\n",
        "            'MAPE_Train', 'MAPE_Test',\n",
        "            'MAE_Train', 'MAE_Test',\n",
        "            'RMSE_Train', 'RMSE_Test'\n",
        "        ]).to_excel(writer, index=False)"
      ],
      "metadata": {
        "id": "wTSHthkN8pC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 4) LOAD DATA\n",
        "# ===============================================================\n",
        "data_path = '/content/drive/My Drive/Objective1/FFP_Data.xlsx'\n",
        "data = pd.read_excel(data_path)\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "3iwm59QY8zvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 5) SETTINGS\n",
        "# ===============================================================\n",
        "iterations = 30\n",
        "mc_iterations = 5000\n",
        "tfd = tfp.distributions"
      ],
      "metadata": {
        "id": "-L8867mZ9G53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 6) NEGATIVE LOG-LIKELIHOOD LOSS\n",
        "# ===============================================================\n",
        "def NLL(y_true, distr):\n",
        "    \"\"\"Normal negative log-likelihood loss.\"\"\"\n",
        "    return -distr.log_prob(y_true)"
      ],
      "metadata": {
        "id": "hQCk7Vd69K1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 7) MODEL BUILDER (MCD-ANN)\n",
        "# ===============================================================\n",
        "def build_model():\n",
        "    \"\"\"Define Monte Carlo Dropout ANN with probabilistic output.\"\"\"\n",
        "    inputs = tf.keras.Input(shape=(X.shape[1],))\n",
        "    x = tf.keras.layers.Dense(30, activation='relu')(inputs)\n",
        "    x = tf.keras.layers.Dropout(0.1)(x, training=True)\n",
        "    x = tf.keras.layers.Dense(20, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.1)(x, training=True)\n",
        "    x = tf.keras.layers.Dense(2)(x)\n",
        "    outputs = tfp.layers.DistributionLambda(\n",
        "        lambda t: tfd.Normal(\n",
        "            loc=t[..., :1],\n",
        "            scale=1e-3 + tf.math.softplus(0.05 * t[..., 1:])\n",
        "        )\n",
        "    )(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.009), loss=NLL)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ud8JJ2WJ9MEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 8) MONTE CARLO PREDICTION FUNCTION\n",
        "# ===============================================================\n",
        "def mc_predict_full_distribution(X_input):\n",
        "    \"\"\"Generate mean, epistemic & aleatoric stds, and 95% CI via MC sampling.\"\"\"\n",
        "    preds_mean, preds_std, full_samples = [], [], []\n",
        "\n",
        "    for _ in range(mc_iterations):\n",
        "        pred = model(X_input)\n",
        "        mu = pred.mean().numpy().flatten()\n",
        "        sigma = pred.stddev().numpy().flatten()\n",
        "        preds_mean.append(mu)\n",
        "        preds_std.append(sigma)\n",
        "        full_samples.append(np.random.normal(loc=mu, scale=sigma))\n",
        "\n",
        "    preds_mean = np.array(preds_mean)\n",
        "    preds_std = np.array(preds_std)\n",
        "    full_samples = np.array(full_samples)\n",
        "\n",
        "    mean_pred = np.mean(preds_mean, axis=0)\n",
        "    epistemic_std = np.std(preds_mean, axis=0)\n",
        "    aleatoric_std = np.sqrt(np.mean(preds_std ** 2, axis=0))\n",
        "    lower_95 = np.percentile(full_samples, 2.5, axis=0)\n",
        "    upper_95 = np.percentile(full_samples, 97.5, axis=0)\n",
        "\n",
        "    return mean_pred, epistemic_std, aleatoric_std, lower_95, upper_95"
      ],
      "metadata": {
        "id": "ZbBOISxy9OH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 9) TRAINING LOOP WITH MCD PREDICTIONS AND EXCEL EXPORT\n",
        "# ===============================================================\n",
        "total_start_time = time.time()\n",
        "\n",
        "for iteration in tqdm(range(iterations), desc=\"Iterations\"):\n",
        "    iter_start_time = time.time()\n",
        "\n",
        "    # -----------------------------\n",
        "    # Split data (70/15/15)\n",
        "    # -----------------------------\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=iteration)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=iteration)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Normalize features\n",
        "    # -----------------------------\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Build and train model\n",
        "    # -----------------------------\n",
        "    model = build_model()\n",
        "    model.fit(X_train, y_train, epochs=1000, verbose=False, validation_data=(X_val, y_val))\n",
        "\n",
        "    # -----------------------------\n",
        "    # Predict with full MC sampling\n",
        "    # -----------------------------\n",
        "    mean_train, epi_train, alea_train, low_train, up_train = mc_predict_full_distribution(X_train)\n",
        "    mean_test, epi_test, alea_test, low_test, up_test = mc_predict_full_distribution(X_test)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Save predictions (train/test)\n",
        "    # -----------------------------\n",
        "    train_df = pd.DataFrame({\n",
        "        'Actual': y_train.flatten(),\n",
        "        'Predicted_Mean': mean_train,\n",
        "        'Epistemic_Std': epi_train,\n",
        "        'Aleatoric_Std': alea_train,\n",
        "        'Lower_95CI': low_train,\n",
        "        'Upper_95CI': up_train\n",
        "    })\n",
        "    with pd.ExcelWriter(training_predictions_file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
        "        train_df.to_excel(writer, sheet_name=f'Iter_{iteration+1}', index=False)\n",
        "\n",
        "    test_df = pd.DataFrame({\n",
        "        'Actual': y_test.flatten(),\n",
        "        'Predicted_Mean': mean_test,\n",
        "        'Epistemic_Std': epi_test,\n",
        "        'Aleatoric_Std': alea_test,\n",
        "        'Lower_95CI': low_test,\n",
        "        'Upper_95CI': up_test\n",
        "    })\n",
        "    with pd.ExcelWriter(testing_predictions_file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
        "        test_df.to_excel(writer, sheet_name=f'Iter_{iteration+1}', index=False)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Save metrics\n",
        "    # -----------------------------\n",
        "    metrics_row = pd.DataFrame([{\n",
        "        'Iteration': iteration + 1,\n",
        "        'R2_Train': r2_score(y_train, mean_train),\n",
        "        'R2_Test':  r2_score(y_test, mean_test),\n",
        "        'MAPE_Train': mean_absolute_percentage_error(y_train, mean_train),\n",
        "        'MAPE_Test':  mean_absolute_percentage_error(y_test, mean_test),\n",
        "        'MAE_Train':  mean_absolute_error(y_train, mean_train),\n",
        "        'MAE_Test':   mean_absolute_error(y_test, mean_test),\n",
        "        'RMSE_Train': np.sqrt(mean_squared_error(y_train, mean_train)),\n",
        "        'RMSE_Test':  np.sqrt(mean_squared_error(y_test, mean_test)),\n",
        "    }])\n",
        "\n",
        "    existing_metrics = pd.read_excel(metrics_file_path)\n",
        "    with pd.ExcelWriter(metrics_file_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
        "        metrics_row.to_excel(writer, index=False, header=False, startrow=len(existing_metrics) + 1)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Timing info\n",
        "    # -----------------------------\n",
        "    iter_time = time.time() - iter_start_time\n",
        "    print(f\"Iteration {iteration+1} took {iter_time:.2f} seconds\")\n",
        "\n",
        "    if iteration == 0:\n",
        "        est = iter_time * iterations\n",
        "        print(f\"Estimated total time: {est/60:.2f} minutes\")"
      ],
      "metadata": {
        "id": "EulDFXnO9P-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 10) RUNTIME SUMMARY\n",
        "# ===============================================================\n",
        "total_end_time = time.time()\n",
        "print(f\"Actual total time: {(total_end_time - total_start_time)/60:.2f} minutes\")"
      ],
      "metadata": {
        "id": "uyLgB6e49T5l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}