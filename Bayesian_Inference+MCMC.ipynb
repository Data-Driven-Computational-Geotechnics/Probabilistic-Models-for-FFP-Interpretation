{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Imports & Setup\n",
        "# ============================\n",
        "\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "tfY2NCPGHr6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Mount Drive\n",
        "# ============================\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============================\n",
        "# Configuration\n",
        "# ============================\n",
        "DATA_PATH = '/content/drive/My Drive/Objective1/Bayesian_Inference/Objective1_bayesian_data.xlsx'\n",
        "OUT_DIR = '/content/drive/My Drive/Objective1/Bayesian_Inference'\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "FORM_CONFIG = {\n",
        "    \"semi_log\": {\"SRC_mu\": -1.7209, \"iterations\": 1},\n",
        "    \"power\": {\"SRC_mu\": -2.41, \"iterations\": 1},\n",
        "    \"ihs\": {\"SRC_mu\": -2.6886, \"iterations\": 100},\n",
        "}\n",
        "\n",
        "METRICS_XLSX = os.path.join(OUT_DIR, 'final_metrics_ALL.xlsx')\n",
        "POSTERIOR_XLSX = os.path.join(OUT_DIR, 'final_posterior_percentiles_ALL.xlsx')\n",
        "PREDICT_XLSX = os.path.join(OUT_DIR, 'predictions_actual_vs_predicted_ALL.xlsx')"
      ],
      "metadata": {
        "id": "-pvbvye3HvEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Performance and Model Functions\n",
        "# ============================\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return mape, rmse, mae, r2\n",
        "\n",
        "log10 = lambda x: pm.math.log(x) / np.log(10.0)\n",
        "asinh = pm.math.asinh\n",
        "\n",
        "def build_qs_estimated(formulation, m, a, rho, A, v, d, Cd, SRC):\n",
        "    g = 9.81\n",
        "    numerator = (m * g) - (m * a) - (0.5 * rho * Cd * A * (v ** 2))\n",
        "    vr = v / (d * 0.55)\n",
        "    if formulation == \"semi_log\":\n",
        "        denom = A * (1 + log10(vr) * SRC)\n",
        "    elif formulation == \"power\":\n",
        "        denom = A * (vr ** SRC)\n",
        "    elif formulation == \"ihs\":\n",
        "        denom = A * (1 + asinh(vr) * SRC)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown formulation: {formulation}\")\n",
        "    return pm.Deterministic('qs_estimated', (numerator / denom) / 1000.0)"
      ],
      "metadata": {
        "id": "1Vt2jAN5Hy4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Bayesian Inference\n",
        "# ============================\n",
        "def run_one_formulation(formulation_key, cfg, data, predictions_writer):\n",
        "    SRC_mu = cfg[\"SRC_mu\"]\n",
        "    iters = cfg[\"iterations\"]\n",
        "    metrics_rows = []\n",
        "    posterior_list = []\n",
        "    for i in range(iters):\n",
        "        rs = np.random.randint(0, 10_000)\n",
        "        train_df, test_df = train_test_split(data, test_size=0.8, random_state=rs)\n",
        "        m_train = train_df['Mass'].values\n",
        "        a_train = train_df['Acceleration'].values\n",
        "        rho_train = train_df['Density'].values\n",
        "        A_train = train_df['Area'].values\n",
        "        v_train = train_df['Velocity'].values\n",
        "        d_train = train_df['Diameter'].values\n",
        "        y_train = train_df['Static Tip Resistance'].values\n",
        "        m_test = test_df['Mass'].values\n",
        "        a_test = test_df['Acceleration'].values\n",
        "        rho_test = test_df['Density'].values\n",
        "        A_test = test_df['Area'].values\n",
        "        v_test = test_df['Velocity'].values\n",
        "        d_test = test_df['Diameter'].values\n",
        "        y_test = test_df['Static Tip Resistance'].values\n",
        "\n",
        "        with pm.Model() as model:\n",
        "            m_d = pm.Data(\"m_train\", m_train)\n",
        "            a_d = pm.Data(\"a_train\", a_train)\n",
        "            rho_d = pm.Data(\"rho_train\", rho_train)\n",
        "            A_d = pm.Data(\"A_train\", A_train)\n",
        "            v_d = pm.Data(\"v_train\", v_train)\n",
        "            d_d = pm.Data(\"d_train\", d_train)\n",
        "            SRC = pm.LogNormal('SRC', mu=SRC_mu, sigma=0.472)\n",
        "            Cd = pm.LogNormal('Cd', mu=-0.468, sigma=0.472)\n",
        "            sigma = pm.Uniform('sigma', lower=0, upper=100)\n",
        "            qs_estimated = build_qs_estimated(formulation_key, m_d, a_d, rho_d, A_d, v_d, d_d, Cd, SRC)\n",
        "            pm.Normal('qs_likelihood', mu=qs_estimated, sigma=sigma, observed=y_train)\n",
        "            trace = pm.sample(10000, tune=2000, step=pm.Metropolis(), chains=2, cores=1, return_inferencedata=True)\n",
        "\n",
        "        summ = az.summary(trace, var_names=['Cd', 'SRC', 'sigma'], hdi_prob=0.95)\n",
        "        summ.index.name = 'param'\n",
        "        posterior_list.append(summ)\n",
        "        sigma_mean = trace.posterior['sigma'].mean().item()\n",
        "\n",
        "        with model:\n",
        "            pm.set_data({\"m_train\": m_test, \"a_train\": a_test, \"rho_train\": rho_test, \"A_train\": A_test, \"v_train\": v_test, \"d_train\": d_test})\n",
        "            pp_test = pm.sample_posterior_predictive(trace, var_names=['qs_estimated'])\n",
        "        with model:\n",
        "            pm.set_data({\"m_train\": m_train, \"a_train\": a_train, \"rho_train\": rho_train, \"A_train\": A_train, \"v_train\": v_train, \"d_train\": d_train})\n",
        "            pp_train = pm.sample_posterior_predictive(trace, var_names=['qs_estimated'])\n",
        "\n",
        "        pred_train_mean = pp_train.posterior_predictive['qs_estimated'].mean(dim=(\"chain\", \"draw\")).values\n",
        "        pred_train_std = np.sqrt(pp_train.posterior_predictive['qs_estimated'].var(dim=(\"chain\", \"draw\")).values + sigma_mean**2)\n",
        "        pred_test_mean = pp_test.posterior_predictive['qs_estimated'].mean(dim=(\"chain\", \"draw\")).values\n",
        "        pred_test_std = np.sqrt(pp_test.posterior_predictive['qs_estimated'].var(dim=(\"chain\", \"draw\")).values + sigma_mean**2)\n",
        "\n",
        "        mape_tr, rmse_tr, mae_tr, r2_tr = calculate_metrics(y_train, pred_train_mean)\n",
        "        mape_te, rmse_te, mae_te, r2_te = calculate_metrics(y_test, pred_test_mean)\n",
        "        metrics_rows.append({\n",
        "            'Formulation': formulation_key,\n",
        "            'Iteration': i + 1,\n",
        "            'R_squared_train': r2_tr,\n",
        "            'MAE_train': mae_tr,\n",
        "            'MAPE_train': mape_tr,\n",
        "            'RMSE_train': rmse_tr,\n",
        "            'R_squared_test': r2_te,\n",
        "            'MAE_test': mae_te,\n",
        "            'MAPE_test': mape_te,\n",
        "            'RMSE_test': rmse_te\n",
        "        })\n",
        "\n",
        "        df_train = pd.DataFrame({'Actual': y_train, 'Predicted_Mean': pred_train_mean, 'Predicted_Std': pred_train_std})\n",
        "        df_test = pd.DataFrame({'Actual': y_test, 'Predicted_Mean': pred_test_mean, 'Predicted_Std': pred_test_std})\n",
        "        df_train.to_excel(predictions_writer, sheet_name=f'{formulation_key.upper()}_Train_Iter_{i+1}', index=False)\n",
        "        df_test.to_excel(predictions_writer, sheet_name=f'{formulation_key.upper()}_Test_Iter_{i+1}', index=False)\n",
        "    return metrics_rows, posterior_list"
      ],
      "metadata": {
        "id": "l3cXSX0CH2As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Run All Formulations\n",
        "# ============================\n",
        "data = pd.read_excel(DATA_PATH)\n",
        "all_metrics = []\n",
        "posterior_blocks = []\n",
        "with pd.ExcelWriter(PREDICT_XLSX, engine='openpyxl') as pred_writer:\n",
        "    for form_key, cfg in FORM_CONFIG.items():\n",
        "        m_rows, post_list = run_one_formulation(form_key, cfg, data, pred_writer)\n",
        "        all_metrics.extend(m_rows)\n",
        "        for j, dfp in enumerate(post_list, start=1):\n",
        "            dfp = dfp.copy()\n",
        "            dfp['Formulation'] = form_key\n",
        "            dfp['Iteration'] = j\n",
        "            posterior_blocks.append(dfp)"
      ],
      "metadata": {
        "id": "VgkFUSKoH5P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Save Results\n",
        "# ============================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "metrics_df.to_excel(METRICS_XLSX, index=False)\n",
        "if posterior_blocks:\n",
        "    posterior_cat = pd.concat(posterior_blocks, axis=0)\n",
        "    cols = ['Formulation', 'Iteration'] + [c for c in posterior_cat.columns if c not in ('Formulation', 'Iteration')]\n",
        "    posterior_cat = posterior_cat[cols]\n",
        "    with pd.ExcelWriter(POSTERIOR_XLSX, engine='openpyxl') as w:\n",
        "        posterior_cat.to_excel(w, sheet_name='ALL', index=True)\n",
        "        for form_key in FORM_CONFIG.keys():\n",
        "            sub = posterior_cat[posterior_cat['Formulation'] == form_key]\n",
        "            sub.to_excel(w, sheet_name=form_key.upper(), index=True)\n",
        "\n",
        "print(\"All done. Files created:\")\n",
        "print(\" - Metrics:\", METRICS_XLSX)\n",
        "print(\" - Posterior summaries:\", POSTERIOR_XLSX)\n",
        "print(\" - Predictions:\", PREDICT_XLSX)"
      ],
      "metadata": {
        "id": "B9vJTg-mH8vk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}